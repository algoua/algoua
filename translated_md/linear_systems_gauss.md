# Метод Гауса розв'язку системи лінійних рівнянь

Дана система $n$ лінійних алгебраических рівнянь (СЛАР) з $m$ невідомими. Потрібно розв'язати цю систему: визначити, скільки рішень вона має (ні одного, одне або нескінченно багато), а якщо вона має хоча б одне розв'язок, то знайти будь-яке з них.

**Формально** задача ставиться наступним чином: розв'язати систему:

$$
\cases{
a_{11} x_1 + a_{12} x_2 + \ldots + a_{1m} x_m = b_1, \cr
a_{21} x_1 + a_{22} x_2 + \ldots + a_{2m} x_m = b_2, \cr
\ldots \cr
a_{n1} x_1 + a_{n2} x_2 + \ldots + a_{nm} x_m = b_n,
}
$$

де коефіцієнти $a_{ij} (i=1 \ldots n, j=1 \ldots m)$ і $b_i (i = 1 \ldots n)$ відомі, а змінні $x_i (i=1 \ldots m)$ - шукані невідомі.

Удобно матричное уявлення цій задачі:

$$
A x = b,
$$

де $A$ - матриця $n \times m$, составленная з коефіцієнтів $a_{ij}$, $x$ і $b$ - векторы-стовпці висоти $m$.

Варто відзначити, що СЛАР можливо бути не над полем дійсних чисел, а над полем **за модулем** какого-або числа $p$, тобто:

$$
\cases{
a_{11} x_1 + a_{12} x_2 + \ldots + a_{1m} x_m = b_1, \pmod p \cr
a_{21} x_1 + a_{22} x_2 + \ldots + a_{2m} x_m = b_2, \pmod p \cr
\ldots \cr
a_{n1} x_1 + a_{n2} x_2 + \ldots + a_{nm} x_m = b_n \pmod p
}
$$

- алгоритм Гауса працює і для таких систем теж (але цей випадок буде розглянуто нижче в окремому розділі).

## Алгоритм Гауса

Строго кажучи, описаний нижче метод правильно називати методом "Гауса-Жордана" (Gauss-Jordan elimination), оскільки він є вариацией методу Гауса, описаної геодезистом Вильгельмом Жорданом в 1887 р. (варто відзначити, що Вильгельм Жордан не є автором ні теореми Жордана про кривих, ні жордановой алгебри - усе це три різних учёных-однофамильца; крім того, по всій видимості, більш правильної є транскрипция "Йордан", але написание "Жордан" вже закрепилось в русской літературі). Також цікаво замітити, що одночасно з Жорданом (а по деяким даними навіть раніше нього) цей алгоритм придумал Класен (B.-I. Clasen).

### Базовая схема

Кратко кажучи, алгоритм полягає в **последовательном исключении** змінних з кожного рівняння до тих пір, поки в кожному рівнянні не залишиться тільки по однієї змінній. Якщо $n=m$, то можна говорити, що алгоритм Гауса-Жордана стремится привести матрицю $A$ системи до одиничної матриці - адже після того як матриця стала одиничної, розв'язок системи очевидно - розв'язок єдино і задається получившимися коефіцієнтами $b_i$.

При цим алгоритм базується на двох простих эквивалентных преобразованиях системи: у-перших, можна обменивать два рівняння, а у-вторых, будь-яке рівняння можна замінити лінійної комбинацией цій стрічки (з ненульовим коефіцієнтом) і інших стрічок (з произвольными коефіцієнтами).

**На першому кроці** алгоритм Гауса-Жордана ділить першу стрічку на коефіцієнт $a_{11}$. Потім алгоритм додає першу стрічку до іншим рядках з такими коефіцієнтами, аби їх коефіцієнти в першому стовпці обращались в нулі - для цього, очевидно, при прибавлении першо] стрічки до $i$-ой треба домножувати її на $-a_{i1}$. При кожної операції з матрицею $A$ (поділ на число, додаток до однієї стрічки іншої) відповідні операції виробляються і з вектором $b$; в деякому сенсі, він веде собі, як якщо б він був $m+1$-им столбцом матриці $A$.

В результаті, по закінченні першого шага перший стовпець матриці $A$ стане единичным (тобто буде містити одиницю в першо] стрічки і нулі в інших).

Аналогічно виготовляється другий крок алгоритму, тільки тепер розглядається другий стовпець і друга стрічка: спочатку друга стрічка ділиться на $a_{22}$, а потім віднімається від всіх інших стрічок з такими коефіцієнтами, аби обнулять другий стовпець матриці $A$.

І так далі, поки ми не опрацюємо всі стрічки або всі стовпці матриці $A$. Якщо $n=m$, то по побудови алгоритму очевидно, що матриця $A$ вийде одиничної, що нам і потрібно.

### Пошук опорного елементу (pivoting)

Зрозуміло, описана вище схема неполна. Вона працює тільки в тому випадку, якщо на кожному $i$-ом кроці елемент $a_{ii}$ відмінний від нуля - інакше ми просто не зможемо домогтися обнуления інших коефіцієнтів в поточному стовпці шляхом додавання до ним $i$-ой стрічки.

Щоб зробити алгоритм работающим в таких випадках, як раз і існує процес **вибору опорного елементу** (на англійською мові це називається одним словом "pivoting"). Він полягає в тому, що виготовляється перестановка стрічок і/або стовпців матриці, аби в нужном елементі $a_{ii}$ виявилося ненульове число.

Зауважимо, що перестановка стрічок значно простіше реалізується на комп'ютері, ніж перестановка стовпців: адже при обмене місцями двох якихось стовпців треба запам'ятати, що ці дві змінних обменялись місцями, аби потім, при відновленні відповіді, правильно відновити, який відповідь до який змінній відноситься. При перестановки стрічок ніяких таких додаткових дій виробляти не треба.

До счастью, для коректності методу достатньо одних тільки обмінів стрічок (т.н. "partial pivoting", в відміну від "full pivoting", коли обмениваются і стрічки, і стовпці). Але яку ж саме стрічку випливає вибирати для обмена? І правда або, що пошук опорного елементу треба робити тільки тоді, коли поточний елемент $a_{ii}$ нульовий?

Общего відповіді на цей питання не існує. Є разнообразные евристики, однак самою ефективної з них (по соотношению простоти і отдачи) є така **евристика**: в якості опорного елементу випливає брати найбільший за модулем елемент, причому виробляти пошук опорного елементу і обмен з ним треба **завжди**, а не тільки коли це необхідно (тобто не тільки тоді, коли $a_{ii}=0$).

Іншими словами, перед виконанням $i$-ой фази алгоритму Гауса-Жордана з евристикою partial pivoting необхідно знайти в $i$-ом стовпці серед елементів з індексами від $i$ до $n$ максимальний за модулем, і обміняти стрічку з цим елементом з $i$-ой рядком.

По-перше, ця евристика дозволить розв'язати СЛАР, навіть якщо по ходу розв'язку буде случаться так, що елемент $a_{ii}=0$. По-друге, що вельми немаловажно, ця евристика покращує **численную устойчивость** алгоритму Гауса-Жордана.

Без цій евристики, навіть якщо система така, що на кожної $i$-ой фазі $a_{ii} \ne 0$ - алгоритм Гауса-Жордана відпрацює, але в підсумку накапливающаяся похибка можливо виявитися настільки огромной, що навіть для матриць розміру близько $20$ похибка буде перевершувати сам відповідь.

### Вырожденные випадки

Отже, якщо останавливаться на алгоритмі Гауса-Жордана з partial pivoting, то, затверджується, якщо $m=n$ і система невырождена (тобто має ненульовий визначник, що означає, що вона має єдине розв'язок), то описаний вище алгоритм повністю відпрацює і придёт до одиничної матриці $A$ (доведення цього, тобто того, що ненульовий опорний елемент завжди буде перебувати, тут не наводиться).

Розглянемо тепер **загальний випадок** - коли $n$ і $m$ не обов'язково рівні. Припустимо, що опорний елемент на $i$-ом кроці не знайшовся. Це означає, що в $i$-ом стовпці всі стрічки, починаючи з поточній, містять нулі. Стверджується, що в цим випадку ця $i$-ая змінна не можливо бути визначена, і є **независимой змінній** (можливо приймати довільне значення). Щоб алгоритм Гауса-Жордана продолжил свою роботу для всіх подальших змінних, в такий ситуації треба просто пропустити поточний $i$-ый стовпець, не увеличивая при цим номер поточній стрічки (можна сказати, що ми виртуально видаляємо $i$-ый стовпець матриці).

Отже, деякі змінні в процесі роботи алгоритму можуть оказываться незалежними. Зрозуміло, що коли кількість $m$ змінних більше кількості $n$ рівнянь, то як мінімум $m-n$ змінних обнаружатся незалежними.

В цілому, якщо обнаружилась хоча б одна незалежна змінна, то вона можливо приймати довільне значення, в то час як інші (зависимые) змінні будуть выражаться через її. Це означає, що, коли ми працюємо в поле дійсних чисел, система потенциально має **нескінченно багато рішень** (якщо ми розглядаємо СЛАР за модулем, то кількість розв'язків буде рівне цьому модулю в степені кількості незалежних змінних). Втім, випливає бути акуратним: треба пам'ятати про тому, що навіть якщо були обнаружены незалежні змінні, тим не менш СЛАР **можливо не мати рішень зовсім**. Це відбувається, коли в залишилися необработанными уравнениях (тих, до яких алгоритм Гауса-Жордана не дошёл, тобто це рівняння, в яких залишилися тільки незалежні змінні) є хоча б один ненульовий вільний член.

Втім, простіше це перевірити явной підстановкою знайденого розв'язку: всім незалежними змінним присвоїти нулевые значення, зависимым змінним присвоїти знайдені значення, і підставити це розв'язок в поточну СЛАР.

## Реалізація

Наведемо тут реалізацію алгоритму Гауса-Жордана з евристикою partial pivoting (вибором опорного елементу як максимуму по колонки).

На вхід функції $\rm gauss()$ передається сама матриця системи $a$. Останній стовпець матриці $a$ - це в наших старих позначеннях стовпець $b$ свободных коефіцієнтів (так сделано для зручності програмування - т.до. в самому алгоритмі всі операції зі свободными коефіцієнтами $b$ повторяют операції з матрицею $A$).

Функція повертає кількість розв'язків системи ($0$, $1$ або $\infty$) (нескінченність позначена в коді специальной константою $\rm INF$, якій можна задати будь-яке велике значення). Якщо хоча б одне розв'язок існує, то воно повертається в векторі $\rm ans$.

<!--- TODO: specify code snippet id -->
``` cpp
int gauss(vector<vector<double>> a, vector<double> &ans) {
    int n = (int)a.size();
    int m = (int)a[0].size() - 1;

    vector<int> where(m, -1);
    for (int col = 0, row = 0; col < m && row < n; ++col) {
        int sel = row;
        for (int i = row; i < n; ++i)
            if (abs(a[i][col]) > abs(a[sel][col]))
                sel = i;
        if (abs(a[sel][col]) < EPS)
            continue;
        for (int i = col; i <= m; ++i)
            swap(a[sel][i], a[row][i]);
        where[col] = row;

        for (int i = 0; i < n; ++i)
            if (i != row) {
                double c = a[i][col] / a[row][col];
                for (int j = col; j <= m; ++j)
                    a[i][j] -= a[row][j] * c;
            }
        ++row;
    }

    ans.assign(m, 0);
    for (int i = 0; i < m; ++i)
        if (where[i] != -1)
            ans[i] = a[where[i]][m] / a[where[i]][i];
    for (int i = 0; i < n; ++i) {
        double sum = 0;
        for (int j = 0; j < m; ++j)
            sum += ans[j] * a[i][j];
        if (abs(sum - a[i][m]) > EPS)
            return 0;
    }

    for (int i = 0; i < m; ++i)
        if (where[i] == -1)
            return INF;
    return 1;
}
```

В функції підтримуються два покажчика - на поточний стовпець $\rm col$ і поточну стрічку $\rm row$.

Також заводиться вектор $\rm where$, в якому для кожної змінній записано, в який стрічки повинна вона вийти (іншими словами, для кожного стовпчика записан номер стрічки, в якій цей стовпець відмінний від нуля). Цей вектор потрібен, оскільки деякі змінні могли не "определиться" в під час розв'язку (тобто це незалежні змінні, яким можна присвоїти довільне значення - наприклад, в наведеної реалізації це нулі).

Реалізація використовує технику partial pivoting, производя пошук стрічки з максимальним за модулем елементом, і переставляя потім цю стрічку в позицію $\rm row$ (хоча явну перестановку стрічок можна замінити обменом двох індексів в деякому масиві, на практиці це не дасть реального выигрыша, т.до. на обмены тратится $O(n^2)$ операцій).

В реалізації в цілях простоти поточна стрічка не ділиться на опорний елемент - так що в підсумку по закінченні роботи алгоритму матриця стає не одиничної, а диагональной (втім, мабуть, поділ стрічки на ведущий елемент дозваляє декілька зменшити виникають похибки).

Після знаходження розв'язку воно подставляется назад в матрицю - аби перевірити, має або система хоча б одне розв'язок або ні. Якщо перевірка знайденого розв'язку пройшла успешно, то функція повертає $1$ або $\infty$ - в залежності від того, є або хоча б одна незалежна змінна або ні.

## Асимптотика

Оцінимо асимптотику полученного алгоритму. Алгоритм складається з $m$ фаз, на кожної з яких відбувається:

* пошук і перестановка опорного елементу - за час $O(n+m)$ при використанні евристики "partial pivoting" (пошук максимуму в стовпці)
* якщо опорний елемент в поточному стовпці був знайдений - то додаток поточного рівняння до всім іншим уравнениям - за час $O(nm)$

Очевидно, перший пункт має меншу асимптотику, ніж другий. Зауважимо також, що другий пункт виконується не більш $\min(n,m)$ раз - стільки, скільки можливо бути зависимых змінних в СЛАР.

Таким чином, **підсумкова асимптотика** алгоритму приймає вид $O(\min(n,m) \cdot n m)$.

При $n = m$ ця оцінка перетворюється в $O(n^3)$.

Зауважимо, що коли СЛАР розглядається не в поле дійсних чисел, а в поле за модулем два, то систему можна розв'язувати набагато швидше - про цим див. нижче в розділі "Розв'язок СЛАР за модулем".

### Більш точная оцінка числа дій

Для простоти выкладок будемо вважати, що $n = m$.

Як ми вже знаємо, час роботи всього алгоритму фактично визначається часом, затрачиваемым на виняток поточного рівняння з інших.

Це можливо відбуватися на кожному з $n$ кроків, при цим поточний рівняння прибавляется до всім $n-1$ іншим. При прибавлении робота йде тільки зі столбцами, починаючи з поточного. Таким чином, в сумі виходить $n^3 / 2$ операцій.

## Дополнения

### Ускорение алгоритму: поділ його на прямої і зворотний хід

Добиться двукратного прискорення алгоритму можна, рассмотрев іншу його версію, більш класичну, коли алгоритм розбивається на фази прямого і зворотнього ходу.

В цілому, в відміну від описаного вище алгоритму, можна приводити матрицю не до диагональному увазі, а до **треугольному увазі** - коли всі елементи строго нижче главной діагоналі рівні нулю.

Система з трикутною матрицею вирішується тривіально - спочатку з останнього рівняння зразу знаходиться значення останньої змінній, потім знайдене значення подставляется в предпоследнее рівняння і знаходиться значення предпоследней змінній, і так далі. Цей процес і називається **зворотним ходом** алгоритму Гауса.

**Прямой хід** алгоритму Гауса - це алгоритм, аналогічний описаного вище алгоритму Гауса-Жордана, за одним винятком: поточна змінна исключается не з всіх рівнянь, а тільки з рівнянь після поточного. В результаті цього дійсно виходить не диагональная, а треугольная матриця.

Разница в тому, що прямої хід працює **швидше** алгоритму Гауса-Жордана - оскільки в середньому він робить в два рази менше прибавлений одного рівняння до іншому. Обратный хід працює за $O(nm)$, що в будь-якому випадку асимптотично швидше прямого ходу.

Таким чином, якщо $n=m$, то даний алгоритм буде робити вже $n^3/4$ операцій - що в два рази менше алгоритму Гауса-Жордана.

### Розв'язок СЛАР за модулем

Для розв'язку СЛАР за модулем можна застосовувати описаний вище алгоритм, він зберігає свою коректність.

Зрозуміло, тепер стає непотрібним використовувати які-то хитрые техніки вибору опорного елементу - достатньо знайти будь-який ненульовий елемент в поточному стовпці.

Якщо модуль простий, то ніяких складнощів взагалі не виникає - происходящие по ходу роботи алгоритму Гауса ділення не создают особливих проблем.

Особливо замечателен **модуль, рівний двом**: для нього всі операції з матрицею можна виробляти дуже ефективно. Наприклад, отнимание однієї стрічки від іншої за модулем два - це насправді їх симметрическая різницю ("xor"). Таким чином, весь алгоритм можна значно прискорити, сжав всю матрицю в битовые маски і оперируя тільки ними. Наведемо тут нову реалізацію основний частини алгоритму Гауса-Жордана, використовуючи стандартний контейнер C++ "bitset":

<!--- TODO: specify code snippet id -->
``` cpp
int gauss(vector<bitset<N>> a, int n, int m, bitset<N> &ans) {
    vector<int> where(m, -1);
    for (int col = 0, row = 0; col < m && row < n; ++col) {
        for (int i = row; i < n; ++i)
            if (a[i][col]) {
                swap(a[i], a[row]);
                break;
            }
        if (!a[row][col])
            continue;
        where[col] = row;

        for (int i = 0; i < n; ++i)
            if (i != row && a[i][col])
                a[i] ^= a[row];
        ++row;
    }
```

Як можна замітити, реалізація стала навіть трохи коротше, при тому, що вона значно швидше старої реалізації - а саме, швидше в $32$ рази за рахунок битового стиснення. Також випливає відзначити, що розв'язок систем за модулем два на практиці працює дуже швидко, оскільки випадки, коли від однієї стрічки треба віднімати іншу, відбуваються достатньо редко (на розріджених матрицах цей алгоритм можливо працювати за час швидше порядку квадрата від розміру, ніж куба).

Якщо модуль **довільний** (не обов'язково простий), то усе стає декілька складніше. Зрозуміло, що користуючись [Китайской теоремою про залишки](chinese_theorem), ми сводим задачу з довільним модулем тільки до модулям увазі "ступінь простого". [ дальнейший текст був скрыт, т.до. це непроверенная інформація - можливо, неправильный спосіб розв'язку ]

Нарешті, розглянемо питання **числа рішень СЛАР за модулем**. Відповідь на нього достатньо простий: кількість розв'язків рівне $p^k$, де $p$ - модуль, $k$ - число незалежних змінних.

### Трохи про різних способах вибору опорного елементу

Як вже говорилося вище, однозначного відповіді на цей питання ні.

Евристика "partial pivoting", яка заключалась в пошуку максимального елементу в поточному стовпці, працює на практиці вельми неплохо. Також виявляється, що вона дає практично той ж результат, що і "full pivoting" - коли опорний елемент шукається серед елементів цілої підматриці - починаючи з поточній стрічки і з поточного стовпчика.

Але цікаво відзначити, що обидві ці евристики з пошуком максимального елементу, фактично, дуже залежать від того, наскільки були промасштабированы исходные рівняння. Наприклад, якщо одне з рівнянь системи помножити на миллион, то це рівняння майже наверняка буде вибрано в якості провідного на першому ж кроці. Це здається достатньо странным, тому логичен перехід до трохи більш складної евристиці - так называемому **"implicit pivoting"**.

Евристика implicit pivoting полягає в тому, що елементи різних стрічок сравниваются так, як якщо б обидві стрічки були пронормированы таким чином, що максимальний за модулем елемент в них був б рівний одиниці. Для реалізації цій техніки треба просто підтримувати поточний максимум в кожної стрічки (або підтримувати кожну стрічку так, аби максимум в ній був рівний одиниці за модулем, але це можливо привести до збільшення накапливаемой похибки).

### Улучшение знайденого відповіді

Оскільки, незважаючи на різні евристики, алгоритм Гауса-Жордана усе рівне можливо приводити до великим погрешностям на специальных матрицах навіть розмірів порядку $50$ - $100$.

В зв'язку з цим, отриманий алгоритмом Гауса-Жордана відповідь можна покращити, применив до нього який-або простий чисельний метод - наприклад, метод простий ітерації.

Таким чином, розв'язок перетворюється в двухшаговое: спочатку виконується алгоритм Гауса-Жордана, потім - який-або чисельний метод, принимающий в якості начальных данних розв'язок, отримане на першому кроці.

Такий прийом дозваляє декілька розширити множину задач, решаемых алгоритмом Гауса-Жордана з приемлемой погрешностью.

## Література

* \book{William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery}{Numerical Recipes: The Art of Scientific Computing}{2007}{numerical_recipes.pdf}
* \book{Anthony Ralston, Philip Rabinowitz}{A first course in numerical analysis}{2001}
