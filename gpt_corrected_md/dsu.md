# Система множин, які не перетинаються

У даній статті розглядається структура даних **"система неперетинних множин"** (англ. "disjoint-set-union", або просто "DSU").

Ця структура даних надає наступні можливості. Спочатку є кілька елементів, кожен з яких знаходиться в окремій множині. За одну операцію можна **об'єднати дві будь-які множини**, а також можна **запитати, в якій множині** зараз знаходиться зазначений елемент. Також, в класичному варіанті, вводиться ще одна операція - створення нового елементу, який додається до окремої множини.

Таким чином, базовий інтерфейс цієї структури даних складається всього з трьох операцій:

* ${\rm add\_to\_set}(x)$ - **додає** новий елемент $x$, поміщаючи його в нову множину, що складається з одного нього.

* ${\rm об'єднати\_множини}(x,y)$ - об'єднує дві задані множини (множину, в якій знаходиться елемент $x$, і множину, в якій знаходиться елемент $y$).

* ${\rm find\_set}(x)$ - **повертає, в якій множині** знаходиться зазначений елемент $x$. Насправді при цьому повертається один з елементів множини (званий **представником** або **лідером** (в англомовній літературі "leader")). Цей представник вибирається в кожній множині самою структурою даних (і може змінюватися з течією часу, а саме, після викликів ${\rm union\_sets}()$).

Наприклад, якщо виклик ${\rm знайди\_множину}()$ для якихось двох елементів повернув одне і те ж значення, то це означає, що ці елементи знаходяться в одній і тій же множині, а в іншому випадку - в різних множинах.

Описувана нижче структура даних дозволяє виконувати кожну з цих операцій майже за $O(1)$ в середньому (більш детально про асимптотику див. нижче після опису алгоритму).

Також у одному з підрозділів статті описано альтернативний варіант реалізації DSU, що дозволяє досягти асимптотики $O(\log n)$ в середньому на один запит при $m \ge n$; а при $m \gg n$ (тобто $m$ значно більше $n$) - навіть часу $O(1)$ в середньому на запит (див. "Зберігання DSU у вигляді явного списку множин").

## Побудова ефективної структури даних

Опеределимося спочатку, у якому вигляді ми будемо зберігати усю інформацію.

Множини елементів ми будемо зберігати у вигляді **дерев**: одне дерево відповідає одній множині. Корінь дерева - це представник (лідер) множини.

При реалізації цього ми заводимо масив ${\rm parent}$, в якому для кожного елементу зберігається посилання на його батька в дереві. Для коренів дерев ми вважаємо, що їхнім батьком є вони самі (тобто посилання зациклюється в цьому місці).

### Наївна реалізація

Ми вже можемо написати першу реалізацію системи, яка не містить перетинів множин. Вона буде досить неефективною, але потім ми покращимо її за допомогою двох прийомів, отримавши в підсумку майже константний час роботи.

Отже, вся інформація про множини елементів зберігається за допомогою масиву ${\rm parent}$.

Щоб створити новий елемент (операція ${\rm make\_set}(v)$), ми просто створюємо дерево з коренем у вершині $v$, позначаючи, що її батьком є вона сама.

Щоб об'єднати дві множини (операція ${\rm union\_sets}(a,b)$), ми спочатку знаходимо лідерів множини, в якій знаходиться $a$, і множини, в якій знаходиться $b$. Якщо лідери збігаються, то нічого не робимо - це означає, що множини вже об'єднані. В іншому випадку можна просто вказати, що предок вершини $b$ дорівнює $a$ (або навпаки) - тим самим приєднати одне дерево до іншого.

Нарешті, реалізація операції пошуку лідера (${\rm знайти\_корінь}(v)$) проста: ми піднімаємося по батьківським вершинам від вершини $v$, поки не дійдемо до кореня, тобто поки посилання на батька не вказує на ніщо. Цю операцію зручніше реалізувати рекурсивно (особливо це буде зручно пізніше, у зв'язку з оптимізаціями).

<!--- TODO: specify code snippet id -->
``` cpp
void make_set(int v) { parent[v] = v; }

int find_set(int v) {
    if (v == parent[v])
        return v;
    return find_set(parent[v]);
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b)
        parent[b] = a;
}
```

Втім, така реалізація системи, що не перетинаються множин, є дуже неефективною. Легко побудувати приклад, коли після декількох об'єднань множин виникне ситуація, що множина стане деревом, що перетворилося на довгий ланцюг. У результаті кожний виклик ${\rm find\_set}()$ буде працювати на такому тесті за час порядку глибини дерева, тобто за $O(n)$.

Це дуже далеко від тієї асимптотики, яку ми збиралися отримати (константний час роботи). Тому розглянемо дві оптимізації, які дозволять (навіть застосовані окремо) значно прискорити роботу.

### Евристика стиснення шляху

Ця евристика призначена для прискорення роботи ${\rm знайти\_множину}()$.

Вона полягає в тому, що після виклику ${\rm знайди\_множину}(v)$ ми знаходимо шуканого лідера $p$ множини, і запам'ятовуємо, що у вершині $v$ і всіх пройдених по шляху вершинах - саме цей лідер $p$. Простіше за все це зробити, перенаправивши їх ${\rm батько}[]$ на цю вершину $p$.

Таким чином, у масиві предків ${\rm parent}[]$ змінюється зміст: тепер це **стиснутий масив предків**, тобто для кожної вершини там може зберігатися не безпосередній предок, а предок предка, предок предка предка, тощо.

З іншого боку, зрозуміло, що не можна зробити так, щоб ці вказівники ${\rm parent}$ завжди вказували на лідера: інакше при виконанні операції ${\rm union\_sets}()$ довелося б оновлювати лідерів у $O(n)$ елементах.

Таким чином, масив ${\rm parent}[]$ можна розглядати як масив предків, який, можливо, частково стиснутий.

Нова реалізація операції ${\rm find\_set}()$ виглядає наступним чином:

<!--- TODO: specify code snippet id -->
``` cpp
int find_set(int v) {
    if (v == parent[v])
        return v;
    return parent[v] = find_set(parent[v]);
}
```

Така проста реалізація робить все, що задумувалось: спочатку шляхом рекурсивних викликів знаходиться лідер множини, а потім, в процесі розкрутки стеку, цей лідер присвоюється посиланням ${\rm parent}$ для всіх пройдених елементів.

Реалізувати цю операцію можна й нерекурсивно, але тоді доведеться здійснити два проходи по дереву: перший знайде шуканого лідера, другий - проставить його всім вершинам шляху. Однак на практиці нерекурсивна реалізація не дає суттєвої переваги.

#### Оцінка асимптотики при застосуванні евристики стиснення шляхів

Покажемо, що застосування однієї евристики стиснення шляхів **дозволяє досягти логарифмічної асимптотики**: $O(\log n)$ на один запит у середньому.

Зауважимо, що, оскільки операція ${\rm union\_sets}()$ складається з двох викликів операції ${\rm find\_set}()$ і ще $O(1)$ операцій, то ми можемо сконцентруватися на доведенні оцінки часу роботи $O(m)$ операцій ${\rm find\_set}()$.

Назвемо **вагою** $w[v]$ вершини $v$ кількість нащадків цієї вершини (включаючи її саму). Ваги вершин, очевидно, можуть тільки збільшуватися в процесі роботи алгоритму.

Назвемо **розмахом ребра** $(a,b)$ різницю ваг кінців цього ребра: $|w[a] - w[b]|$ (очевидно, у вершині-предку вага завжди більша, ніж у вершини-нащадка). Можна помітити, що розмах будь-якого фіксованого ребра $(a,b)$ може збільшуватися тільки в процесі роботи алгоритму.

Крім того, розіб'ємо ребра на **класи**: будемо говорити, що ребро має клас $k$, якщо його довжина належить відрізку $[2^k; 2^{k+1}-1]$. Таким чином, клас ребра - це число від $0$ до $\lceil \log n \rceil$.

Зафіксуємо тепер довільну вершину $x$ і будемо стежити за зміною ребра в її предка: спочатку його немає (поки вершина $x$ є лідером), потім проводиться ребро з $x$ в деяку вершину (коли множина з вершиною $x$ приєднується до іншої множини), і потім можливі зміни при стисканні шляхів під час викликів ${\rm find\_path}$. Зрозуміло, що нас цікавить асимптотика тільки останнього випадку (при стисканні шляхів): всі інші випадки вимагають $O(1)$ часу на один запит.

Розглянемо роботу деякого виклику операції ${\rm find\_set}$: він проходить у дереві вздовж деякого **шляху**, стираючи всі ребра цього шляху і перенаправляючи їх до лідера.

Розглянемо цей шлях і виключимо з розгляду останнє ребро кожного класу (тобто не більш ніж по одному ребру з класу $0, 1, \ldots \lceil \log n \rceil$). Тим самим ми виключили $O(\log n)$ ребер з кожного запиту.

Розглянемо тепер усі **інші** ребра цього шляху. Для кожного такого ребра, якщо воно має клас $k$, випливає, що в цьому шляху є ще одне ребро класу $k$ (інакше ми були б зобов'язані виключити поточне ребро, як єдиного представника класу $k$). Таким чином, після стиснення шляху це ребро заміниться на ребро класу як мінімум $k+1$. Враховуючи, що зменшувати вагу ребра не можливо, ми отримуємо, що для кожної вершини, затронутої запитом $\rm find\_path$, ребро в її предка або було виключено, або строго збільшило свій клас.

Звідси ми отримуємо остаточну асимптотику роботи $m$ запитів: $O((n+m) \log n)$. Це означає, що час виконання одного запиту у середньому є логарифмічним, якщо $m \ge n$. Російське слово "запит" можна замінити на українське "запитання".

### Евристика з'єднання за рангом

Розглянемо іншу евристику, яка сама по собі може прискорити час роботи алгоритму, а в поєднанні з евристикою стиснення шляхів може досягти практично константного часу роботи на один запит в середньому.

Ця евристика полягає в невеликій зміні роботи ${\rm union\_sets}$: якщо в наївній реалізації те, яке дерево буде приєднано до якого, визначається випадково, то тепер ми будемо це робити на основі **рангів**.

Є два варіанти рангової евристики: в одному варіанті рангом дерева називається **кількість вершин**, а в другому - **глибина дерева** (точніше, верхня межа на глибину дерева, оскільки при застосуванні евристики стиснення шляхів реальна глибина дерева може зменшуватися).

У обох варіантах суть евристики одна і та ж: під час виконання $\rm union\_sets$ будемо приєднувати дерево з меншим рангом до дерева з більшим рангом.

Наведемо реалізацію **рангової евристики на основі розмірів дерев**:

<!--- TODO: specify code snippet id -->
``` cpp
void make_set(int v) {
    parent[v] = v;
    size[v] = 1;
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (size[a] < size[b])
            swap(a, b);
        parent[b] = a;
        size[a] += size[b];
    }
}
```

Наведемо реалізацію **рангової евристики на основі глибини дерев**:

<!--- TODO: specify code snippet id -->
``` cpp
void make_set(int v) {
    parent[v] = v;
    rank[v] = 0;
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (rank[a] < rank[b])
            swap(a, b);
        parent[b] = a;
        if (rank[a] == rank[b])
            ++rank[a];
    }
}
```

Обидва варіанти ранжувальної евристики є еквівалентними з точки зору асимптотики, тому на практиці можна застосовувати будь-який з них.

#### Оцінка асимптотики при застосуванні рангової евристики

Покажемо, що асимптотика роботи системи, що не перетинаються множин, при використанні тільки рангової евристики (без евристики стиснення шляхів), буде логарифмічною на один запит в середньому: $O(\log n)$.

Тут ми покажемо, що при будь-якому з двох варіантів рангової евристики глибина кожного дерева буде величиною $O(\log n)$, що автоматично означатиме логарифмічну асимптотику для запиту $\rm find\_set$, і, отже, запиту $\rm union\_sets$.

Розглянемо **розрядкову евристику по глибині дерева**. Покажемо, що якщо розрядність дерева рівна $k$, то це дерево містить як мінімум $2^k$ вершин (звідси буде автоматично дотримуватися, що розрядність, а, значить, і глибина дерева, є величина $O(\log n)$). Доводити будемо за допомогою індукції: для $k=0$ це очевидно. При стисканні шляхів глибина може тільки зменшитися. Розрядність дерева збільшується з $k-1$ до $k$, коли до нього приєднується дерево розрядності $k-1$; застосовуючи до цих двох дерев розміру $k-1$ припущення індукції, отримуємо, що нове дерево розрядності $k$ дійсно матиме як мінімум $2^k$ вершин, що і потрібно довести.

Розглянемо тепер **рангову евристику за розміром дерев**. Покажемо, що якщо розмір дерева дорівнює $k$, то його висота не перевищує $\lfloor \log k \rfloor$. Доведемо це за допомогою індукції: для $k=1$ твердження є вірним. При стисканні шляхів глибина може тільки зменшитися, тому стиснення шляхів не порушує цього. Нехай тепер об'єднуються два дерева розмірів $k_1$ і $k_2$; тоді за припущенням індукції їх висоти менше або дорівнюють, відповідно, $\lfloor \log k_1 \rfloor$ і $\lfloor \log k_2 \rfloor$. Без втрати загальності припустимо, що перше дерево більше ($k_1 \ge k_2$), тому після їх об'єднання глибина отриманого дерева з $k_1+k_2$ вершин стане рівною:

$$
h = \max ( \lfloor \log k_1 \rfloor, 1 + \lfloor \log k_2 \rfloor ).
$$

Щоб завершити доведення, потрібно показати, що:

$$
h ~ \stackrel{?}{\le} ~ \lfloor \log (k_1+k_2) \rfloor,
$$

$$
2^h = \max ( 2 ^ {\lfloor \log k_1 \rfloor}, 2 ^ {\lfloor \log 2 k_2 \rfloor} ) ~ \stackrel{?}{\le} ~ 2 ^ {\lfloor \log (k_1+k_2) \rfloor},
$$

що є майже очевидною нерівністю, оскільки $k_1 \le k_1+k_2$ і $2 k_2 \le k_1+k_2$.

### Об'єднання евристик: стиснення шляху плюс рангова евристика

Як вже згадувалося вище, спільне застосування цих евристик дає найкращий результат, в підсумку досягаючи практично постійного часу роботи.

Ми не будемо наводити тут доведення асимптотики, оскільки воно дуже об'ємне (див., наприклад, Кормен, Лейзерсон, Рівест, Штайн "Алгоритми. Побудова і аналіз"). Вперше це доведення було проведено Тар'яном (1975 р.).

Остаточний результат такий: при спільному застосуванні евристик стиснення шляхів і злиття за рангом час роботи на один запит складає $O(\alpha(n))$ в середньому, де $\alpha(n)$ - **зворотна функція Аккермана**, яка зростає дуже повільно, настільки повільно, що для всіх розумних обмежень $n$ вона **не перевищує 4** (приблизно для $n \le 10^{600}$).

Саме тому, що множини не перетинаються, вірно говорити про "майже константний час роботи" системи.

Наведемо тут **підсумкову реалізацію системи, яка не містить перетинів множин**, що використовує обидві зазначені евристики (використовується рангова евристика щодо глибини дерев)

<!--- TODO: specify code snippet id -->
``` cpp
void make_set (int v) {
    parent[v] = v;
    rank[v] = 0;
}

int find_set(int v) {
    if (v == parent[v])
        return v;
    return parent[v] = find_set(parent[v]);
}

void union_sets (int a, int b) {
    a = find_set (a);
    b = find_set (b);
    if (a != b) {
        if (rank[a] < rank[b])
            swap (a, b);
        parent[b] = a;
        if (rank[a] == rank[b])
            ++rank[a];
    }
}
```

## Застосування в завданнях та різних поліпшень

У цьому розділі ми розглянемо кілька застосувань структури даних "система неперетинних множин", як простих, так і з використанням деяких поліпшень структури даних.

### Підтримка компонент зв'язності графу

Це один з очевидних застосувань структури даних "система неперетинних множин", яке, очевидно, стимулювало вивчення цієї структури.

Формально задачу можна сформулювати так: спочатку задано порожній граф, поступово до цього графа можуть додаватися вершини та неорієнтовані ребра, а також надходять запити $(a,b)$ - "чи лежать вершини $a$ і $b$ в однакових або різних компонентах зв'язності?".

Безпосередньо застосовуючи тут описану вище структуру даних, ми отримуємо розв'язок, що обробляє один запит на додавання вершини/ребра або запит на перевірку двох вершин - майже за константний час в середньому.

Враховуючи, що практично та сама задача ставиться при використанні [**алгоритму прима знаходження мінімального остовного дерева**](mst_prima), ми одразу ж отримуємо [покращену версію цього алгоритму](mst_prima_with_dsu), яка працює практично за лінійний час.

Іноді на практиці зустрічається *інвертована версія цієї задачі*: спочатку є граф з деякими вершинами і ребрами, і надходять запити на видалення ребер. Якщо задача дана в офлайні, тобто ми заздалегідь можемо дізнатися всі запити, то розв'язувати цю задачу можна наступним чином: перевернемо задачу задом наперед: будемо вважати, що у нас є порожній граф, в який можуть додаватися ребра (спочатку додамо ребро останнього запиту, потім передостаннього, і т.д.). Тим самим в результаті інвертування цієї задачі ми прийшли до звичайної задачі, розв'язок якої описувався вище.

### Пошук компонент зв'язності на зображенні

Одне з застосувань DSU полягає у розв'язанні наступної задачі: є зображення $n \times m$ пікселів. Спочатку всі пікселі білі, але потім на ньому малюється кілька чорних пікселів. Потрібно визначити розмір кожної "білої" компоненти зв'язності на кінцевому зображенні.

Для розв'язку ми просто перебираємо всі білі клітини зображення, для кожної клітини перебираємо її чотири сусіди, і якщо сусід також є білим, то викликаємо ${\rm union\_sets}()$ від цих двох вершин. Таким чином, у нас буде DSU з $nm$ вершинами, відповідними пікселям зображення. Отримане в підсумку дерево DSU - це шукані компоненти зв'язності.

Дану задачу можна розв'язати простіше з використанням [обходу в глибину](dfs) (або [обходу в ширину](bfs)), однак у описаному тут методі є певна перевага: він можливий для обробки матриці построчно (оперуючи тільки з поточним рядком, попереднім рядком і системою, що не перетинаються множин, побудованою для елементів однієї рядка), тобто використовуючи порядку $O(\min (n, m))$ пам'яті.

### Підтримка додаткової інформації для кожної множини

"Система, яка не перетинається множин", дозволяє легко зберігати будь-яку додаткову інформацію, що стосується безлічі.

Простий приклад - це **розміри множин**: як їх зберігати, було описано при описі рангової евристики (інформація там записувалась для поточного лідера множини).

Таким чином, разом із лідером кожної множини можна зберігати будь-яку додаткову інформацію, необхідну в конкретній задачі.

### Застосування DSU для стиснення "стрибків" по відрізку. Задача про фарбування підвідрізків в офлайні

Одне з поширених застосувань DSU полягає у тому, що якщо є набір елементів, і з кожного елементу виходить по одній грані, то ми можемо швидко (за майже константний час) знаходити кінцеву точку, в яку ми потрапимо, якщо будемо рухатися вздовж ребер з заданої початкової точки.

Наглядним прикладом цього застосування є **задача про фарбування відрізків**: є відрізок довжини $L$, кожна клітина якого (тобто кожний кусочок довжини $1$) має нульовий колір. Надходять запити у вигляді $(l,r,c)$ - перекрасити відрізок $[l;r]$ в колір $c$. Потрібно знайти підсумковий колір кожної клітини. Запити вважаються відомими заздалегідь, тобто задача вирішується в офлайні.

Для розв'язку можна використати DSU-структуру, яка для кожної клітини буде зберігати посилання на найближчу праву непофарбовану клітинку. Таким чином, спочатку кожна клітина вказує на саму себе, а після фарбування першого підвідрізку - клітина перед початком підвідрізку буде вказувати на клітинку після кінця підвідрізку.

Тепер, щоб розв'язати задачу, ми розглядаємо запити перефарбування **у зворотному порядку**: від останнього до першого. Для виконання запиту ми просто кожен раз з допомогою нашої DSU знаходимо саму ліву непофарбовану клітинку всередині відрізку, перефарбовуємо її і перебрасуємо вказівник з неї на наступну справа порожню клітинку.

Таким чином, ми тут фактично використовуємо DSU з евристикою стиснення шляхів, але без рангової евристики (тобто нам важливо, хто стане лідером після злиття). Отже, підсумкова асимптотика складе $O(\log n)$ на запит (проте з невеликою константою порівняно з іншими структурами даних).

Реалізація:

<!--- TODO: specify code snippet id -->
``` cpp
void init() {
    for (int i = 0; i < L; ++i)
        make_set(i);
}

void process_query(int l, int r, int c) {
    for (int v = l;;) {
        v = find_set(v);
        if (v >= r)
            break;
        answer[v] = c;
        parent[v] = v + 1;
    }
}
```

Втім, можна реалізувати цей розв'язок **за допомогою рангової евристики**: будемо зберігати для кожної множини в деякому масиві ${\rm end}[]$, де ця множина закінчується (тобто саму праву точку). Таким чином, можна буде об'єднувати дві множини в одну за їх ранговою евристикою, після чого проставляти отриманій множині нову праву межу. Тим самим ми отримаємо розв'язок за $O(\alpha(n))$.

### Підтримка відстаней до лідера

Іноді в окремих додатках системи, де множини не перетинаються, може виникнути потреба підтримувати відстань до кореня дерева (тобто суму довжин ребер в дереві від поточної вершини до кореня).

Якби не було евристики стиснення шляхів, то не виникало б жодних складнощів - відстань до кореня просто дорівнювала б числу рекурсивних викликів, які здійснила функція $\rm find\_set$.

Однак у результаті стиснення шляхів декілька ребер могли злитися в одне. Тому, крім кожної вершини, необхідно зберігати додаткову інформацію про **довжину поточного ребра від вершини до її батька**.

При реалізації зручно представляти, що масив ${\rm parent}[]$ та функція $\rm find\_set$ тепер повертають не одне число, а пару чисел: вершину-лідера та відстань до неї

<!--- TODO: specify code snippet id -->
``` cpp
void make_set(int v) {
    parent[v] = make_pair(v, 0);
    rank[v] = 0;
}

pair<int, int> find_set(int v) {
    if (v != parent[v].first) {
        int len = parent[v].second;
        parent[v] = find_set(parent[v].first);
        parent[v].second += len;
    }
    return parent[v];
}

void union_sets(int a, int b) {
    a = find_set(a).first;
    b = find_set(b).first;
    if (a != b) {
        if (rank[a] < rank[b])
            swap(a, b);
        parent[b] = make_pair(a, 1);
        if (rank[a] == rank[b])
            ++rank[a];
    }
}
```

### Підтримка парності довжини шляхів і задача про перевірку двудольного графа в онлайн

За аналогією з довжиною шляху до лідера, так само можна підтримувати парність довжини шляху до нього. Чому ж це застосування було виділено в окремий пункт?

Справа в тому, що зазвичай вимога збереження парності шляху виникає в зв'язку з наступною **задачею**: спочатку заданий порожній граф, до якого можуть додаватися ребра, а також надходять запити у вигляді "чи існує компонента зв'язності, що містить дану вершину, **двудольну**?".

Для розв'язання цієї задачі ми можемо завести систему неперетинаючих множин для зберігання компонент зв'язності і зберігати у кожної вершини парність довжини шляхів до її лідера. Тим самим ми можемо швидко перевірити, чи призведе додавання зазначеного ребра до порушення двудольності графа: якщо кінці ребра лежать в одній і тій же компоненті зв'язності і мають однакові парності довжини шляхів до лідера, то додавання цього ребра призведе до утворення циклу непарної довжини і перетворення поточної компоненти на недвудольну.

Головна складність, з якою ми стикаємося при цьому, - це те, що ми повинні аккуратно, з урахуванням парностей, виконувати об'єднання двох дерев у функції $\rm union\_sets$.

Якщо ми додаємо ребро $(a,b)$, що з'єднує дві компоненти зв'язності в одну, то при приєднанні одного дерева до іншого ми повинні вказати йому таку парність, щоб у результаті в вершинах $a$ і $b$ отримувалися різні парності довжини шляхів.

Виведемо **формулу**, за якою повинна бути ця парність, що встановлюється лідером одного множини при приєднанні його до лідера іншої множини. Позначимо через $x$ парність довжини шляху від вершини $a$ до лідера її множини, через $y$ - парність довжини шляху від вершини $b$ до лідера її множини, а через $t$ - шукану парність, яку ми повинні присвоїти приєднуваному лідеру. Якщо множина з вершиною $a$ приєднується до безлічі з вершиною $b$, стаючи під деревом, то після приєднання у вершини $b$ її парність не зміниться і залишиться рівною $y$, а у вершини $a$ парність стане рівною $x \oplus t$ (символом $\oplus$ тут позначена операція XOR (симетрична різниця)). Нам потрібно, щоб ці дві парності відрізнялися, тобто їх XOR був рівний одиниці. Отже, отримуємо рівняння на $t$:

$$
x \oplus t \oplus y = 1,
$$

розв'язуючи яке, знаходимо:

$$
t = x \oplus y \oplus 1.
$$

Таким чином, незалежно від того, яку множину приєднується до якої, слід використовувати вказану формулу для визначення парності ребра, яке проводиться від одного вузла до іншого.

Наведемо **реалізацію** DSU з підтримкою парності. Як і в попередньому пункті, у цілях зручності ми використовуємо пари для зберігання предків і результату операції $\rm find\_set$. Крім того, для кожної множини ми зберігаємо в масиві ${\rm bipartite}[]$, чи вона є дводольною чи ні.

<!--- TODO: specify code snippet id -->
``` cpp
void make_set(int v) {
    parent[v] = make_pair(v, 0);
    rank[v] = 0;
    bipartite[v] = true;
}

pair<int, int> find_set(int v) {
    if (v != parent[v].first) {
        int parity = parent[v].second;
        parent[v] = find_set(parent[v].first);
        parent[v].second ^= parity;
    }
    return parent[v];
}

void add_edge(int a, int b) {
    pair<int, int> pa = find_set(a);
    a = pa.first;
    int x = pa.second;

    pair<int, int> pb = find_set(b);
    b = pb.first;
    int y = pb.second;

    if (a == b) {
        if (x == y)
            bipartite[a] = false;
    } else {
        if (rank[a] < rank[b])
            swap(a, b);
        parent[b] = make_pair(a, x ^ y ^ 1);
        bipartite[a] &= bipartite[b];
        if (rank[a] == rank[b])
            ++rank[a];
    }
}

bool is_bipartite(int v) { return bipartite[find_set(v).first]; }
```

### Алгоритм знаходження RMQ (мінімум на відрізку) за $O(\alpha(n))$ в середньому в офлайні

Формально задача ставиться наступним чином: необхідно реалізувати структуру даних, яка підтримує два узагальнені запити: додавання зазначеного числа ${\rm insert}(i)$ ($i = 1 \ldots n$) та пошук і вилучення поточного мінімального числа ${\rm extract\_min}()$. Будемо вважати, що кожне число додається рівно один раз.

Крім того, припустимо, що вся послідовність запитів відома нам заздалегідь, тобто задача є офлайн.

**Ідея розв'язку** наступна. Замість того, щоб по черзі відповідати на кожен запит, переберемо число $i = 1 \ldots n$, і визначимо, відповідь на який запит це число має бути. Для цього нам потрібно знайти перший необроблений запит, який йде після додавання ${\rm insert}(i)$ цього числа - легко зрозуміти, що це і є той запит, відповідь на який є число $i$.

Таким чином, тут виходить ідея, схожа на **задачу про фарбування відрізків**.

Можна отримати розв'язок за $O(\log n)$ в середньому на запит, якщо ми відмовимося від рангової евристики і будемо просто зберігати в кожному елементі посилання на найближчий справа запит ${\rm extract\_min}()$, а також використовувати стиснення шляхів для підтримки цих посилань після об'єднання.

Також можна отримати розв'язок за $O(\alpha(n))$, якщо використовувати рангову евристику та зберігати в кожному множині номер позиції, де воно закінчується (тобто, що в попередньому варіанті розв'язку досягалося автоматично завдяки тому, що посилання завжди йшли тільки вправо, - тепер потрібно буде зберігати явно).

### Алгоритм знаходження LCA (найменшого спільного предка в дереві) за $O(\alpha(n))$ в середньому в офлайні

Алгоритм Тар'яна знаходження LCA за $O(1)$ в середньому в режимі онлайн описаний в [відповідної статті](lca_linear_offline). Цей алгоритм вигідно відрізняється від інших алгоритмів пошуку LCA своєї простотою (особливо по порівняно з [оптимальним алгоритмом Фарах-Колтона-Бендера](lca_linear)).

### Зберігання DSU у вигляді явного списку множин. Застосування цієї ідеї при злитті різних структур даних

Одним з альтернативних способів зберігання DSU є збереження кожної множини у вигляді **списку її елементів, що зберігається явно**. При цьому кожен елемент також містить посилання на представника (лідера) його множини.

На перший погляд здається, що це неефективна структура даних: при об'єднанні двох множин ми повинні будемо додати один список в кінець іншого, а також оновити лідера у всіх елементів одного з двох списків.

Однак, як виявляється, застосування **вагової евристики**, аналогічної описаній вище, дозволяє істотно знизити асимптотику роботи: до $O(m + n \log n)$ для виконання $m$ запитів над $n$ елементами.

Під ваговою евристикою мається на увазі, що завжди **слід додавати меншу з двох множин до більшої**. Додавання ${\rm union\_sets}()$ одного множини до іншого легко реалізувати за час порядку розміру додається множини, а пошук лідера ${\rm find\_set}()$ - за час $O(1)$ при такому способі зберігання.

Доведемо **асимптотику** $O(m + n \log n)$ для виконання $m$ запитів. Зафіксуємо довільний елемент $x$ і прослідкуємо, як на нього впливали операції об'єднання ${\rm union\_sets}$. Коли на елемент $x$ вплинули вперше, ми можемо стверджувати, що розмір його нової множини буде як мінімум $2$. Коли на $x$ вплинули вдруге - можна стверджувати, що він потрапить в множину розміру не менше $4$ (тобто ми додаємо меншу множину до більшої). І так далі - отримуємо, що на елемент $x$ могло вплинути максимум $\lceil \log n \rceil$ операцій об'єднання. Таким чином, в сумі по всім вершинам це становить $O(n \log n)$, плюс по $O(1)$ на кожний запит - що і потрібно довести.

Наведемо приклад **впровадження**:

<!--- TODO: specify code snippet id -->
``` cpp
vector<int> lst[MAXN];
int parent[MAXN];

void make_set(int v) {
    lst[v] = vector<int>(1, v);
    parent[v] = v;
}

int find_set(int v) { return parent[v]; }

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (lst[a].size() < lst[b].size())
            swap(a, b);
        while (!lst[b].empty()) {
            int v = lst[b].back();
            lst[b].pop_back();
            parent[v] = a;
            lst[a].push_back(v);
        }
    }
}
```

Також цю ідею додавання елементів меншої множини до більшої можна використовувати і поза рамками DSU, при розв'язанні інших задач.

Наприклад, розглянемо наступну **задачу**: дано дерево, кожному листку якого приписано яке-небудь число (одне й те саме число можливо зустрічатися декілька разів у різних листках). Потрібно для кожної вершини дерева дізнатися кількість різних чисел у її піддереві.

Застосувавши в цій задачі цю ж ідею, можна отримати таке розв'язання: запустимо [обхід в глибину](dfs) по дереву, який буде повертати вказівник на ${\rm set}$ чисел - список всіх чисел у піддереві цієї вершини. Отже, щоб отримати відповідь для поточної вершини (якщо, звісно, вона не є листком) - потрібно викликати обхід в глибину від усіх дітей цієї вершини та об'єднати всі отримані ${\rm set}$ в один, розмір якого і буде відповіддю для поточної вершини. Для ефективного об'єднання кількох ${\rm set}$ в один саме застосуємо описаний вище прийом: будемо об'єднувати два множини, просто додаючи по одному елементу меншого множини в більший. В результаті ми отримаємо розв'язок за $O(n \log^2 n)$, оскільки додавання одного елементу в ${\rm set}$ виконується за $O(\log n)$.

### Збереження DSU зі збереженням явної структури дерев. Перепідвішування. Алгоритм пошуку мостів у графі за $O(\alpha(n))$ в середньому в онлайні

Одне з потужних застосувань структури даних "системи, що не перетинаються множин", полягає в тому, що вона дозволяє зберігати одночасно **як стислу, так і нестислу структуру дерев**. Стисла структура може бути використана для швидкого з'єднання дерев і перевірки належності двох вершин одному дереву, а нестисла - наприклад, для пошуку шляху між двома заданими вершинами, або інших обходів структури дерева.

При реалізації цього означає, що крім звичайного для DSU масиву стиснутих предків ${\rm parent}[]$ ми заведемо масив звичайних, нестиснутих, предків ${\rm real\_parent}[]$. Зрозуміло, що підтримування такого масиву ніяк не погіршує асимптотику: зміни в ньому відбуваються тільки при об'єднанні двох дерев, і лише в одному елементі.

З іншого боку, при застосуванні на практиці часто потрібно навчитися з'єднувати два дерева зазначеним ребром, що не обов'язково виходить з їх коренів. Це означає, що у нас немає іншого виходу, крім як **перепідвісити** одне з дерев за зазначеною вершиною, щоб потім ми могли приєднати це дерево до іншого, зробивши корінь цього дерева дочірньою вершиною до другого кінця додаваного ребра.

На перший погляд здається, що операція перепідвішування є дуже затратною і сильно погіршує асимптотику. Насправді, для перепідвішування дерева за вершиною $v$ ми повинні пройтися від цієї вершини до кореня дерева, оновлюючи всюди вказівники ${\rm parent}[]$ і ${\rm real\_parent}[]$.

Однак насправді все не так погано: достатньо лише перепідвісити те з двох дерев, яке менше, щоб отримати асимптотику одного з'єднання, рівну $O(\log n)$ в середньому.

Більш детально (включаючи доведення асимптотики) див. [алгоритм пошуку мостів в графі за $O(\log n)$ в середньому в онлайні](bridge_searching_online).

## Історична ретроспектива

Структура даних "система неперетинних множин" була відома порівняно давно.

Спосіб зберігання цієї структури у вигляді **лісу дерев** був, по всій видимості, вперше описаний Галлером та Фішером в 1964 році (Galler, Fisher "An Improved Equivalence Algorithm"). Однак повний аналіз асимптотики був проведений набагато пізніше.

Евристики стиснення шляхів і з'єднання за рангом, мабуть, були розроблені Макілроєм (McIlroy) і Моррісом (Morris), і, незалежно від них, Тріттером (Tritter).

Деякий час була відома лише оцінка $O(\log^* n)$ на одну операцію в середньому, дана Хопкрофтом та Ульманом в 1973 році ("Set-merging algorithms"). Тут $\log^* n$ - **ітерований логарифм** (це повільно зростаюча функція, але все ж не настільки повільно, як зворотна функція Аккермана).

Вперше оцінку $O(\alpha(n))$, де $\alpha(n)$ - **обернена функція Аккермана**, отримав Тарьян у своїй статті 1975 р. (Tarjan "Efficiency of a Good But Not Linear Set Union Algorithm"). Пізніше, у 1985 р., він разом з Льювеном отримали цю часову оцінку для декількох різних рангових евристик та методів стиснення шляхів (Tarjan, Leeuwen "Worst-Case Analysis of Set Union Algorithms").

Нарешті, Фредман та Сакс у 1989 році довели, що в прийнятій моделі обчислень **будь-який** алгоритм для системи, що не перетинається з множиною, повинен працювати як мінімум за $O(\alpha(n))$ в середньому (Fredman, Saks "The cell probe complexity of dynamic data structures").

Втім, варто відзначити, що існує кілька статей, які спростовують цю тимчасову оцінку та стверджують, що система, яка не перетинається з евристиками стиснення шляхів та об'єднання по рангу, працює за $O(1)$ у середньому: Zhang "The Union-Find Problem Is Linear", Wu, Otoo "A Simpler Proof of the Average Case Complexity of Union-Find with Path Compression".

## Завдання в онлайн-суддях

Список задач, які можна розв'язати з допомогою системи неперетинних множин:

* [TIMUS #1671 "Павутина Анансі" [складність: низька]](http://acm.timus.ru/problem.aspx?space=1&num=1671)

* [CODEFORCES 25D "Дороги не тільки в Берляндії" [складність: середня]](http://codeforces.com/contest/25/problem/D)
* [TIMUS #1003 **"Чётность"** [складність: середня]](http://acm.timus.ru/problem.aspx?space=1&num=1003)

* [SPOJ #1442 **"Chain"** [складність: середня]](http://www.spoj.pl/problems/CHAIN/)

## Література

* \book{Томас Кормен, Чарльз Лейзерсон, Рональд Рівест, Кліффорд Штайн}{Алгоритми: Побудова та аналіз}{2005}{cormen.djvu}
* \book{Kurt Mehlhorn, Peter Sanders}{Algorithms and Data Structures: The Basic Toolbox}{2008}{algorithms_toolbox_mehlhorn.pdf}
* \book{Robert Endre Tarjan}{Efficiency of a Good But Not Linear Set Union Algorithm}{1975}{dsu/Efficiency of a Good But Not Linear Set Union Algorithm. Tarjan.pdf}
* \book{Robert Endre Tarjan, Jan van Leeuwen}{Worst-Case Analysis of Set Union Algorithms}{1985}{dsu/Worst-Case Analysis of Set Union Algorithms. Tarjan, Leeuwen.pdf}