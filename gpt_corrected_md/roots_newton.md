# Метод Ньютона (таємничий) для пошуку коренів

Це ітераційний метод, який був винайдений **Ісааком Ньютоном** близько 1664 року. Проте іноді цей метод називають методом Ньютона-Рафсона (Raphson), оскільки Рафсон винайшов той самий алгоритм на кілька років пізніше за Ньютона, але його стаття була опублікована набагато раніше.

Задача полягає в наступному: дано рівняння:

$$
f(x) = 0.
$$

Потрібно розв'язати це рівняння, а саме знайти один з його коренів (передбачається, що корінь існує). При цьому передбачається, що $f(x)$ є неперервною та диференційованою на відрізку $[a;b]$.

## Алгоритм

Вхідним параметром алгоритму, крім функції $f(x)$, є також **початкове наближення** - деяке $x_0$, від якого алгоритм починає рухатись.

Нехай вже обчислено $x_i$, обчислимо $x_{i+1}$ наступним чином. Проведемо дотичну до графіку функції $f(x)$ у точці $x = x_i$, і знайдемо точку перетину цієї дотичної з віссю абсцис. $x_{i+1}$ вважаємо рівним знайденій точці, і повторюємо весь процес з початку.

Не складно отримати наступну формулу:

$$
x_{i+1} = x_i - \frac{ f(x_i) }{ f^\prime(x_i) }.
$$

Інтуїтивно зрозуміло, що якщо функція $f(x)$ достатньо "добра" (гладка), а $x_i$ знаходиться достатньо близько до кореня, то $x_{i+1}$ буде знаходитись ще ближче до шуканого кореня.

Швидкість збіжності є **квадратичною**, що, умовно кажучи, означає, що кількість точних розрядів у наближеному значенні $x_i$ подвоюється з кожною ітерацією.

## Застосування для обчислення квадратного кореня:

Розглянемо метод Ньютона на прикладі обчислення квадратного кореня.

Якщо підставити $f(x) = \sqrt{x}$, то після спрощення виразу отримуємо:

$$
x_{i+1} = \frac{ x_i + \frac{n}{x_i} }{ 2 }.
$$

Перший типовий варіант задачі полягає в тому, що задано дробове число $n$, і потрібно обчислити його корінь з певною точністю $\rm EPS$:

<!--- TODO: specify code snippet id -->
``` cpp
double n;
cin >> n;
const double EPS = 1E-15;
double x = 1;
for (;;) {
    double nx = (x + n / x) / 2;
    if (abs(x - nx) < EPS)
        break;
    x = nx;
}
printf("%.15lf", x);
```

Інший поширений вид задачі - коли потрібно порахувати цілочисельний корінь (для даного $n$ знайти найбільше $x$ таке, що $x^2 \le n$). Тут доводиться трохи змінювати умову зупинки алгоритму, оскільки можливо станеться так, що $x$ почне "скакати" навколо відповіді. Тому ми додаємо умову, що якщо значення $x$ на попередньому кроці зменшилося, а на поточному кроці намагається збільшитися, то алгоритм потрібно зупинити.

<!--- TODO: specify code snippet id -->
``` cpp
int n;
cin >> n;
int x = 1;
bool decreased = false;
for (;;) {
    int nx = (x + n / x) >> 1;
    if (x == nx || nx > x && decreased)
        break;
    decreased = nx < x;
    x = nx;
}
cout << x;
```

Нарешті, наведемо ще третій варіант - для випадку довгої арифметики. Оскільки число $n$ може бути досить великим, то має сенс звернути увагу на початкове наближення. Очевидно, що чим воно ближче до кореня, тим швидше буде досягнутий результат. Досить простим і ефективним буде брати в якості початкового наближення число $2^{{\rm bits}/2}$, де $\rm bits$ - кількість бітів у числі $n$. Ось код на мові Java, що демонструє цей варіант:

<!--- TODO: specify code snippet id -->
``` cpp
BigInteger n; // вхідні дані

BigInteger a = BigInteger.ONE.shiftLeft(n.bitLength() / 2);
boolean p_dec = false;
for (;;) {
    BigInteger b = n.divide(a).add(a).shiftRight(1);
    if (a.compareTo(b) == 0 || a.compareTo(b) < 0 && p_dec)
        break;
    p_dec = a.compareTo(b) > 0;
    a = b;
}
```

Наприклад, цей код виконується для числа $10^{1000}$ за $60$ мілісекунд, а якщо видалити покращений вибір початкового наближення (просто починати з $1$), то буде виконуватися приблизно $120$ мілісекунд.